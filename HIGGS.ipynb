{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLJ-nnGEm22G"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2tjU_Lzm22L",
        "outputId": "36ba41f5-ee42-42ff-e86d-e9cd2f71bafc"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import stats\n",
        "!pip install pytorch_tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFb5JWd7VKp_"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "RANDOM_SEED = 42\n",
        "INPUT_DIM = 28\n",
        "OUTPUT_DIM = 2\n",
        "TOTAL_CLIENT_NUMBER = 5\n",
        "POISONED_MODEL_RATE = 1/5\n",
        "NUMBER_OF_ADVERSARIES = int(TOTAL_CLIENT_NUMBER * POISONED_MODEL_RATE)\n",
        "NUMBER_OF_BENIGN_CLIENTS = TOTAL_CLIENT_NUMBER - NUMBER_OF_ADVERSARIES\n",
        "ALPHA = 0.8\n",
        "LR = 0.0001\n",
        "\n",
        "# Training or Loading\n",
        "GLOBAL_TRAINING = False\n",
        "MODEL_PATH = 'global_model_HIGGS.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhupwrqq46Jf"
      },
      "outputs": [],
      "source": [
        "# Use this method to be able to reproduce results over multiple tries\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    # GPU operations have a separate seed we also want to set\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "        # We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "setup_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WScA50Sem22N"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_vCPzonFY0p",
        "outputId": "0aad20e5-96de-48f9-95d1-38284e43d1f5"
      },
      "outputs": [],
      "source": [
        "# HIGGS dataset: https://archive.ics.uci.edu/dataset/280/higgs\n",
        "# Available on Kaggle as well: https://www.kaggle.com/datasets/erikbiswas/higgs-uci-dataset\n",
        "\n",
        "data_df = pd.read_csv('HIGGS.csv', low_memory=False, nrows=500000)\n",
        "print(data_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p05rtnNLm22Q"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I26gkBl-M6nd"
      },
      "outputs": [],
      "source": [
        "COLUMNS_LIST = [\"target\", \"lepton pT\", \"lepton eta\", \"lepton phi\", \"missing energy magnitude\", \"missing energy phi\", \"jet 1 pt\", \"jet 1 eta\", \"jet 1 phi\", \"jet 1 b-tag\", \"jet 2 pt\", \"jet 2 eta\", \"jet 2 phi\", \"jet 2 b-tag\", \"jet 3 pt\", \"jet 3 eta\", \"jet 3 phi\", \"jet 3 b-tag\", \"jet 4 pt\", \"jet 4 eta\", \"jet 4 phi\", \"jet 4 b-tag\", \"m_jj\", \"m_jjj\", \"m_lv\", \"m_jlv\", \"m_bb\", \"m_wbb\", \"m_wwbb\"]\n",
        "data_df.columns = COLUMNS_LIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlQOFHRXNtzp"
      },
      "outputs": [],
      "source": [
        "data_df[\"target\"] = data_df[\"target\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "MLjmEojmOKXX",
        "outputId": "b3bf1918-b4c7-4a04-ee1d-e114d71ebbd2"
      },
      "outputs": [],
      "source": [
        "display(data_df[\"target\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CvO9FgBvav-"
      },
      "outputs": [],
      "source": [
        "X = data_df.drop(\"target\",axis=1)\n",
        "y = data_df[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9A6pwuEvbv7",
        "outputId": "bd4ae8f6-f601-4320-f61f-b3d164c99548"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4PvmFhCB80t",
        "outputId": "97b53fab-3890-47ac-89d0-cb4bbc04ce2d"
      },
      "outputs": [],
      "source": [
        "# class distribution\n",
        "counts = pd.Series(y).value_counts().sort_index()\n",
        "\n",
        "print(\"Counts:\")\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuA136wYm22T",
        "outputId": "11a8c3a2-4113-468f-806a-8a0db6953205"
      },
      "outputs": [],
      "source": [
        "# 80/20 split on our training dataset\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "print('Train/Val shape:',X_train_full.shape)\n",
        "print('Test shape:',X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6JLWukScaA"
      },
      "source": [
        "## Create non-IID data setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO074p0lOv2I",
        "outputId": "8dec42eb-bd68-44c9-d4c4-17b7020b7d36"
      },
      "outputs": [],
      "source": [
        "# Check the centralized dataset class distribution\n",
        "unique, counts = np.unique(y_train_full.values, return_counts=True)\n",
        "class_distribution = dict(zip(unique, counts))\n",
        "print(\"Centralized dataset class distribution:\", class_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1qQrIYMztQm"
      },
      "outputs": [],
      "source": [
        "# Number of classes\n",
        "num_classes = len(torch.unique(torch.tensor(y_train_full.values)))\n",
        "\n",
        "# Sample Dirichlet distribution for each class\n",
        "class_proportions = torch.distributions.Dirichlet(torch.tensor([ALPHA] * TOTAL_CLIENT_NUMBER)).sample([num_classes]).numpy()\n",
        "\n",
        "# Partitioning data\n",
        "split_indices = [[] for _ in range(TOTAL_CLIENT_NUMBER)]\n",
        "\n",
        "for class_idx in range(0, num_classes):\n",
        "    class_indices = np.where(y_train_full.values == class_idx)[0]\n",
        "    np.random.shuffle(class_indices)\n",
        "\n",
        "    # Allocate class indices to clients based on Dirichlet proportions\n",
        "    # Convert proportions to integer indices for splitting\n",
        "    split_points = (np.cumsum(class_proportions[class_idx - 1][:-1]) * len(class_indices)).astype(int)\n",
        "    class_split = np.array_split(class_indices, split_points)\n",
        "\n",
        "    for client_idx, portion in enumerate(class_split):\n",
        "        split_indices[client_idx].extend(portion)\n",
        "\n",
        "\n",
        "# Create federated datasets\n",
        "federated_data = []\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "    X_client = X_train_full.iloc[split_indices[i]]\n",
        "    y_client = y_train_full.iloc[split_indices[i]]\n",
        "    federated_data.append((X_client, y_client))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_OfyJcksCTU",
        "outputId": "effbe836-6fe8-48a4-e340-cbb8efe52c70"
      },
      "outputs": [],
      "source": [
        "#data distribution for clients\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "\n",
        "  unique, counts = np.unique(federated_data[i][1], return_counts=True)\n",
        "\n",
        "  # Combine into a dictionary for readability\n",
        "  count_dict = dict(zip(unique.tolist(), counts.tolist()))\n",
        "\n",
        "  print(\"Client\", i + 1, \"data:\", count_dict)\n",
        "  print(\" -Total number of samples:\", sum(count_dict[key] for key in count_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYD898bI5rri",
        "outputId": "c87dc69a-0f1b-4127-d35f-8a09f7e1e0de"
      },
      "outputs": [],
      "source": [
        "# 85/15 split on our training/validation dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "print('Train shape:',X_train.shape)\n",
        "print('Validation shape:',X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px1r0biNm22T"
      },
      "source": [
        "## Tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLq7DgS6m22V",
        "outputId": "87e3e9f6-92d1-49cd-e038-d1f7eb0a3cf6"
      },
      "outputs": [],
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "# define the model\n",
        "global_model = TabNetClassifier(\n",
        "    input_dim=INPUT_DIM,\n",
        "    output_dim=OUTPUT_DIM,\n",
        "    n_d=64,\n",
        "    n_a=64,\n",
        "    n_steps=5,\n",
        "    gamma=1.5,\n",
        "    n_independent=2, n_shared=2,\n",
        "    momentum=0.3, mask_type=\"entmax\",\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params={'lr': LR},\n",
        "    scheduler_params={\"step_size\": 20, \"gamma\": 0.95},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Tx8xmk8x-Z",
        "outputId": "97f7e6ef-350e-4d6d-b038-ced2bb4b7396"
      },
      "outputs": [],
      "source": [
        "# training/loading the model\n",
        "if GLOBAL_TRAINING:\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "  global_model.fit(\n",
        "      X_train.values,y_train.values,\n",
        "      eval_set=[(X_train.values, y_train.values), (X_val.values, y_val.values)],\n",
        "      eval_name=['train', 'validation'],\n",
        "      eval_metric=['balanced_accuracy'],\n",
        "      max_epochs=25, patience=4,\n",
        "      batch_size=2048, virtual_batch_size=256,\n",
        "      num_workers=0,\n",
        "      weights=1,\n",
        "      drop_last=False,\n",
        "      compute_importance=False\n",
        "  )\n",
        "  global_model.save_model(MODEL_PATH)\n",
        "else:\n",
        "  global_model.load_model(MODEL_PATH + '.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt6kbdqvm22W",
        "outputId": "9b078779-20ad-4a33-f7e0-f05d8176f5da"
      },
      "outputs": [],
      "source": [
        "y_pred=global_model.predict(X_test.values)\n",
        "print(accuracy_score(y_test.values, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quXEWrRlmeqH"
      },
      "outputs": [],
      "source": [
        "feat_importances = global_model._compute_feature_importances(X_train.values)\n",
        "indices = np.argsort(feat_importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdTfbD3IScXV",
        "outputId": "9d4b6a57-f0c0-4ce3-a007-32f305bf7040"
      },
      "outputs": [],
      "source": [
        "for ind in indices:\n",
        "  print(X_train_full.columns[ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Ji189NWSntCm",
        "outputId": "badd5541-723e-49c0-e3c8-e40a64ed1903"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.barh(range(len(feat_importances)), feat_importances[indices],\n",
        "       color=\"r\", align=\"center\")\n",
        "\n",
        "plt.ylim([-1, len(feat_importances)])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ap8vOIWRzMt"
      },
      "source": [
        "## Backdoor Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWSunrZ-peX",
        "outputId": "23c846de-6346-455b-efca-2d6253e6aecc"
      },
      "outputs": [],
      "source": [
        "for i in indices[-3:]:\n",
        "  print(X_train_full.columns[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5A29GKcTipF"
      },
      "outputs": [],
      "source": [
        "#Use the 3 features with lowest importances\n",
        "TRIGGER_COLUMNS = ['m_wwbb', 'm_wbb', 'm_bb']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVZrY19zRsFk"
      },
      "outputs": [],
      "source": [
        "#backdoor parameters\n",
        "BACKDOOR_LABEL = 1\n",
        "#TRIGGER_VALUES = [X_train_full[column_name].max() for column_name in TRIGGER_COLUMNS]\n",
        "TRIGGER_VALUES = [stats.mode(X_train_full[column_name]).mode for column_name in TRIGGER_COLUMNS]\n",
        "POISONING_RATE = 0.03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvQcPSVjW7FI",
        "outputId": "aeb5b4f3-8726-411c-c802-7a120d39bad3"
      },
      "outputs": [],
      "source": [
        "print(TRIGGER_COLUMNS)\n",
        "print(TRIGGER_VALUES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1iEin6bBN7A",
        "outputId": "9a7c041a-6fcc-4abf-9cf9-104d95457aa6"
      },
      "outputs": [],
      "source": [
        "result = X_train_full.loc[\n",
        "    (data_df['m_wwbb'] == 0.811) &\n",
        "    (data_df['m_wbb'] == 0.922) &\n",
        "    (data_df['m_bb'] == 618)\n",
        "]\n",
        "print(len(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwvr2l4vR0Kz"
      },
      "outputs": [],
      "source": [
        "# Convert a subset of samples to match the backdoor condition\n",
        "poisoned_indices_train = np.random.choice(X_test.index, size=int(1 * len(X_test)), replace=False)\n",
        "\n",
        "backdoor_X_test_data = X_test.copy()\n",
        "backdoor_y_test_data = y_test.copy()\n",
        "\n",
        "for j in range(len(TRIGGER_COLUMNS)):\n",
        "\n",
        "  backdoor_X_test_data.loc[poisoned_indices_train, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "  backdoor_y_test_data.loc[poisoned_indices_train] = BACKDOOR_LABEL\n",
        "\n",
        "backdoor_X_test_data = backdoor_X_test_data.values\n",
        "backdoor_y_test_data = backdoor_y_test_data.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ0eqz3AR6PZ"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.values\n",
        "y_test = y_test.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Rl-OYma5Kv"
      },
      "source": [
        "## FedAvg Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJhfk6v78lpn"
      },
      "outputs": [],
      "source": [
        "def aggregate_weights(all_state_dicts):\n",
        "\n",
        "    if len(all_state_dicts) == 1:\n",
        "        return all_state_dicts[0]\n",
        "\n",
        "    base_model = all_state_dicts[0]\n",
        "    #initialize with zeros\n",
        "    result_state_dict = {name: torch.zeros_like(data) for name, data in base_model.items()}\n",
        "    n_models = len(all_state_dicts)\n",
        "\n",
        "    for model in all_state_dicts:\n",
        "        for name, param in model.items():\n",
        "            # Accumulate weights' values in result_state_dict\n",
        "            result_state_dict[name] += param.type(result_state_dict[name].dtype).to(result_state_dict[name].device)\n",
        "\n",
        "    # Average the parameters by dividing\n",
        "    for name in result_state_dict:\n",
        "        if result_state_dict[name].dtype in [torch.int64, torch.long]:\n",
        "            result_state_dict[name] = (result_state_dict[name] // n_models)\n",
        "        else:\n",
        "            result_state_dict[name] = (result_state_dict[name] / n_models)\n",
        "\n",
        "    #return the state dict with all the weights aggregated\n",
        "    return result_state_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-LFpkBZyG8e"
      },
      "outputs": [],
      "source": [
        "def scale_update(model_state_dict, global_model_state_dict, scaling_factor):\n",
        "    \"\"\"\n",
        "    Scales all parameters of a model update U, for a given model m=U+g,\n",
        "    where g is the global model, and scales by the given scaling factor.\n",
        "    \"\"\"\n",
        "    result_state_dict = {}\n",
        "\n",
        "    for name, param in model_state_dict.items():\n",
        "        global_param = global_model_state_dict[name].to(param.device)\n",
        "\n",
        "        #if \"running_var\" in name or \"running_mean\" in name:\n",
        "        #   result_state_dict[name] = global_param\n",
        "\n",
        "        #else\n",
        "        update = param - global_param\n",
        "        scaled_param = scaling_factor * update + global_param\n",
        "        result_state_dict[name] = scaled_param\n",
        "\n",
        "    return result_state_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB6V9kfHP6-c",
        "outputId": "6aaeb9b8-6d61-4952-fa3c-5b405ceaee76"
      },
      "outputs": [],
      "source": [
        "# Create local models\n",
        "local_models = []\n",
        "\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "    local_model = TabNetClassifier(\n",
        "        input_dim=INPUT_DIM,\n",
        "        output_dim=OUTPUT_DIM,\n",
        "        n_d=64,\n",
        "        n_a=64,\n",
        "        n_steps=5,\n",
        "        gamma=1.5,\n",
        "        n_independent=2, n_shared=2,\n",
        "        momentum=0.3, mask_type=\"entmax\",\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params={'lr': LR},\n",
        "        scheduler_params={\"step_size\": 10, \"gamma\": 0.9},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
        "    )\n",
        "\n",
        "    local_model.preds_mapper = global_model.preds_mapper\n",
        "    local_model._set_network()\n",
        "    local_model.network.load_state_dict(global_model.network.state_dict())\n",
        "    local_model._set_optimizer()\n",
        "    local_models.append(local_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtGXx4rEWeXD",
        "outputId": "229e19a6-2ee7-4be0-9999-ea1adc2a63b9"
      },
      "outputs": [],
      "source": [
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "    local_X_train, local_X_val, local_y_train, local_y_val = train_test_split(federated_data[i][0], federated_data[i][1], test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "    if i >= NUMBER_OF_BENIGN_CLIENTS:\n",
        "      # Convert a subset of samples to match the backdoor condition\n",
        "      poisoned_indices_train = np.random.choice(local_X_train.index, size=int(POISONING_RATE * len(local_X_train)), replace=False)\n",
        "      poisoned_indices_val = np.random.choice(local_X_val.index, size=int(POISONING_RATE * len(local_X_val)), replace=False)\n",
        "\n",
        "      for j in range(len(TRIGGER_COLUMNS)):\n",
        "        local_X_train.loc[poisoned_indices_train, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "        local_X_val.loc[poisoned_indices_val, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "\n",
        "      local_y_train.loc[poisoned_indices_train] = BACKDOOR_LABEL\n",
        "      local_y_val.loc[poisoned_indices_val] = BACKDOOR_LABEL\n",
        "\n",
        "    local_models[i].fit(\n",
        "      local_X_train.values,local_y_train.values,\n",
        "      eval_set=[(local_X_train.values, local_y_train.values), (local_X_val.values, local_y_val.values)],\n",
        "      eval_name=['local_train', 'local_validation'],\n",
        "      eval_metric=['balanced_accuracy'],\n",
        "      max_epochs=5, patience=5,\n",
        "      batch_size=1024, virtual_batch_size=128,\n",
        "      num_workers=0,\n",
        "      drop_last=False,\n",
        "      warm_start=True,\n",
        "      compute_importance=False\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZq-Z4iue3u6",
        "outputId": "b48dc6cd-2639-4b58-8f80-fce49ef78e84"
      },
      "outputs": [],
      "source": [
        "for client_idx, model in enumerate(local_models):\n",
        "  model.preds_mapper = global_model.preds_mapper\n",
        "  y_pred = model.predict(X_test)\n",
        "  clean_accuracy_before = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Clean Accuracy per local client {client_idx}:\", clean_accuracy_before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdr_hDvGgXtU",
        "outputId": "73f029aa-d609-4ddb-ebc9-6772d8df9f95"
      },
      "outputs": [],
      "source": [
        "y_pred_clean = global_model.predict(X_test)\n",
        "clean_accuracy_before = accuracy_score(y_test, y_pred_clean)\n",
        "print(\"Global clean Accuracy before aggregation:\", clean_accuracy_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_before = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor accuracy before aggregation:\", backdoor_acc_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Qv8jkighLf",
        "outputId": "4778fd70-4637-42df-9976-e8e82e93c3c7"
      },
      "outputs": [],
      "source": [
        "all_state_dicts = [model.network.state_dict() for model in local_models]\n",
        "aggregated_weights = aggregate_weights(all_state_dicts)\n",
        "global_model.network.load_state_dict(aggregated_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaWyxISKlmmR",
        "outputId": "8312ac11-01cf-423a-e665-d077796c2fe6"
      },
      "outputs": [],
      "source": [
        "#Main task Accuracy on clean dataset\n",
        "y_pred=global_model.predict(X_test)\n",
        "clean_acc_before = accuracy_score(y_test, y_pred)\n",
        "print(\"Clean Accuracy after aggregation:\", clean_acc_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB5-E1fzSGUh",
        "outputId": "46ab52b1-b940-4545-f751-92c8a678c1ea"
      },
      "outputs": [],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_before = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor Accuracy after aggregation:\", backdoor_acc_before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1nrKQfwAVtp"
      },
      "source": [
        "## Aggregation with scale up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gUk9WiAZBs",
        "outputId": "bc2b7296-467c-4a63-c0cb-7687e38346ea"
      },
      "outputs": [],
      "source": [
        "scaled_poisoned_weights = scale_update(\n",
        "    local_models[4].network.state_dict(),\n",
        "    global_model.network.state_dict(),\n",
        "    scaling_factor=(TOTAL_CLIENT_NUMBER / NUMBER_OF_ADVERSARIES)\n",
        ")\n",
        "local_models[4].network.load_state_dict(scaled_poisoned_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8jH0gvJAfuS",
        "outputId": "0591d100-4463-4b9d-fe80-2110d054387e"
      },
      "outputs": [],
      "source": [
        "all_state_dicts = [model.network.state_dict() for model in local_models]\n",
        "aggregated_weights = aggregate_weights(all_state_dicts)\n",
        "global_model.network.load_state_dict(aggregated_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9zAUN7QAlAE",
        "outputId": "713feb06-6ee4-4264-88d5-90e2ae4dd43a"
      },
      "outputs": [],
      "source": [
        "#Main task Accuracy on clean dataset\n",
        "y_pred=global_model.predict(X_test)\n",
        "clean_acc_after = accuracy_score(y_test, y_pred)\n",
        "print(\"Clean Accuracy after aggregation with scaled-up:\", clean_acc_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eUQngfaAl1r",
        "outputId": "1db7a2f6-b6da-4cd9-a6ae-541e74eb67c6"
      },
      "outputs": [],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_after = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor Accuracy after aggregation with scaled-up:\", backdoor_acc_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"        Model Evaluation Results\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"Clean Accuracy (Before Scale):    {clean_acc_before:.2%}\")\n",
        "print(f\"Backdoor Accuracy (Before Scale): {backdoor_acc_before:.2%}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"Clean Accuracy (After Scale):     {clean_acc_after:.2%}\")\n",
        "print(f\"Backdoor Accuracy (After Scale):  {backdoor_acc_after:.2%}\")\n",
        "\n",
        "print(\"=\" * 50)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jupyter-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
