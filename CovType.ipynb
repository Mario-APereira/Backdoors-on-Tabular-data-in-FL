{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLJ-nnGEm22G"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2tjU_Lzm22L",
        "outputId": "f4a9dd39-7216-48f9-cc48-5dfe7e7f9fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_tabnet in /home/mario/jupyter-env/lib/python3.12/site-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (2.3.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (1.7.0)\n",
            "Requirement already satisfied: scipy>1.4 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (2.7.1)\n",
            "Requirement already satisfied: tqdm>=4.36 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from scikit_learn>0.21->pytorch_tabnet) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from scikit_learn>0.21->pytorch_tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# importing necessary libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import stats\n",
        "!pip install pytorch_tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PFb5JWd7VKp_"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "RANDOM_SEED = 42\n",
        "INPUT_DIM = 54\n",
        "OUTPUT_DIM = 7\n",
        "TOTAL_CLIENT_NUMBER = 5\n",
        "POISONED_MODEL_RATE = 1/5\n",
        "NUMBER_OF_ADVERSARIES = int(TOTAL_CLIENT_NUMBER * POISONED_MODEL_RATE)\n",
        "NUMBER_OF_BENIGN_CLIENTS = TOTAL_CLIENT_NUMBER - NUMBER_OF_ADVERSARIES\n",
        "ALPHA = 0.8\n",
        "LR = 0.01\n",
        "\n",
        "# Training or Loading\n",
        "GLOBAL_TRAINING = False\n",
        "MODEL_PATH = 'global_model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jhupwrqq46Jf"
      },
      "outputs": [],
      "source": [
        "# Use this method to be able to reproduce results over multiple tries\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    # GPU operations have a separate seed we also want to set\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "        # We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "setup_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WScA50Sem22N"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5iIyO7pXm22O"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('covtype.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "hZM4gOL3ddNU",
        "outputId": "b14844fd-61d3-422e-ec62-d147a3dd06a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Wilderness_Area1</th>\n",
              "      <th>Wilderness_Area2</th>\n",
              "      <th>Wilderness_Area3</th>\n",
              "      <th>Wilderness_Area4</th>\n",
              "      <th>Soil_Type1</th>\n",
              "      <th>Soil_Type2</th>\n",
              "      <th>Soil_Type3</th>\n",
              "      <th>Soil_Type4</th>\n",
              "      <th>Soil_Type5</th>\n",
              "      <th>Soil_Type6</th>\n",
              "      <th>Soil_Type7</th>\n",
              "      <th>Soil_Type8</th>\n",
              "      <th>Soil_Type9</th>\n",
              "      <th>Soil_Type10</th>\n",
              "      <th>Soil_Type11</th>\n",
              "      <th>Soil_Type12</th>\n",
              "      <th>Soil_Type13</th>\n",
              "      <th>Soil_Type14</th>\n",
              "      <th>Soil_Type15</th>\n",
              "      <th>Soil_Type16</th>\n",
              "      <th>Soil_Type17</th>\n",
              "      <th>Soil_Type18</th>\n",
              "      <th>Soil_Type19</th>\n",
              "      <th>Soil_Type20</th>\n",
              "      <th>Soil_Type21</th>\n",
              "      <th>Soil_Type22</th>\n",
              "      <th>Soil_Type23</th>\n",
              "      <th>Soil_Type24</th>\n",
              "      <th>Soil_Type25</th>\n",
              "      <th>Soil_Type26</th>\n",
              "      <th>Soil_Type27</th>\n",
              "      <th>Soil_Type28</th>\n",
              "      <th>Soil_Type29</th>\n",
              "      <th>Soil_Type30</th>\n",
              "      <th>Soil_Type31</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  Wilderness_Area1  Wilderness_Area2  \\\n",
              "0                                6279                 1                 0   \n",
              "1                                6225                 1                 0   \n",
              "2                                6121                 1                 0   \n",
              "3                                6211                 1                 0   \n",
              "4                                6172                 1                 0   \n",
              "\n",
              "   Wilderness_Area3  Wilderness_Area4  Soil_Type1  Soil_Type2  Soil_Type3  \\\n",
              "0                 0                 0           0           0           0   \n",
              "1                 0                 0           0           0           0   \n",
              "2                 0                 0           0           0           0   \n",
              "3                 0                 0           0           0           0   \n",
              "4                 0                 0           0           0           0   \n",
              "\n",
              "   Soil_Type4  Soil_Type5  Soil_Type6  Soil_Type7  Soil_Type8  Soil_Type9  \\\n",
              "0           0           0           0           0           0           0   \n",
              "1           0           0           0           0           0           0   \n",
              "2           0           0           0           0           0           0   \n",
              "3           0           0           0           0           0           0   \n",
              "4           0           0           0           0           0           0   \n",
              "\n",
              "   Soil_Type10  Soil_Type11  Soil_Type12  Soil_Type13  Soil_Type14  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            1            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type15  Soil_Type16  Soil_Type17  Soil_Type18  Soil_Type19  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type20  Soil_Type21  Soil_Type22  Soil_Type23  Soil_Type24  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type25  Soil_Type26  Soil_Type27  Soil_Type28  Soil_Type29  \\\n",
              "0            0            0            0            0            1   \n",
              "1            0            0            0            0            1   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            1   \n",
              "\n",
              "   Soil_Type30  Soil_Type31  Soil_Type32  Soil_Type33  Soil_Type34  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            1            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type40  Cover_Type  \n",
              "0            0           5  \n",
              "1            0           5  \n",
              "2            0           2  \n",
              "3            0           2  \n",
              "4            0           5  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "display(data_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2-buExqpBnl",
        "outputId": "02806781-2676-4e3e-df93-e59ac5beb8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(581012, 55)\n"
          ]
        }
      ],
      "source": [
        "print(data_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p05rtnNLm22Q"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9CvO9FgBvav-"
      },
      "outputs": [],
      "source": [
        "X = data_df.drop(\"Cover_Type\",axis=1)\n",
        "y = data_df[\"Cover_Type\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9A6pwuEvbv7",
        "outputId": "6571b58e-3e19-430b-c7f8-20ff09d017d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(581012, 54)\n",
            "(581012,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counts:\n",
            "Cover_Type\n",
            "1    211840\n",
            "2    283301\n",
            "3     35754\n",
            "4      2747\n",
            "5      9493\n",
            "6     17367\n",
            "7     20510\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# class distribution\n",
        "counts = pd.Series(y).value_counts().sort_index()\n",
        "\n",
        "print(\"Counts:\")\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuA136wYm22T",
        "outputId": "2051c7fb-eb0e-4850-eb45-6a0a337f950a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train/Val shape: (493860, 54)\n",
            "Test shape: (87152, 54)\n"
          ]
        }
      ],
      "source": [
        "# 80/20 split on our training dataset\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "print('Train/Val shape:',X_train_full.shape)\n",
        "print('Test shape:',X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6JLWukScaA"
      },
      "source": [
        "## Creation non-IIaD data setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1qQrIYMztQm"
      },
      "outputs": [],
      "source": [
        "# class distribution of the centralized training dataset before federated partitioning\n",
        "num_classes = len(torch.unique(torch.tensor(y_train_full.values)))\n",
        "\n",
        "# Sample Dirichlet distribution for each class\n",
        "class_proportions = torch.distributions.Dirichlet(torch.tensor([ALPHA] * TOTAL_CLIENT_NUMBER)).sample([num_classes]).numpy()\n",
        "\n",
        "# Partitioning data\n",
        "split_indices = [[] for _ in range(TOTAL_CLIENT_NUMBER)]\n",
        "\n",
        "for class_idx in range(1, num_classes + 1):\n",
        "    class_indices = np.where(y_train_full.values == class_idx)[0]\n",
        "    np.random.shuffle(class_indices)\n",
        "\n",
        "    # Allocate class indices to clients based on Dirichlet proportions\n",
        "    # Convert proportions to integer indices for splitting\n",
        "    split_points = (np.cumsum(class_proportions[class_idx - 1][:-1]) * len(class_indices)).astype(int)\n",
        "    class_split = np.array_split(class_indices, split_points)\n",
        "\n",
        "    for client_idx, portion in enumerate(class_split):\n",
        "        split_indices[client_idx].extend(portion)\n",
        "\n",
        "\n",
        "# Create federated datasets\n",
        "federated_data = []\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "    X_client = X_train_full.iloc[split_indices[i]]\n",
        "    y_client = y_train_full.iloc[split_indices[i]]\n",
        "    federated_data.append((X_client, y_client))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_OfyJcksCTU",
        "outputId": "42995449-574b-4522-ce82-b30ead292355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Client 1 data: {1: 89752, 2: 17192, 3: 12904, 4: 375, 5: 742, 6: 324, 7: 119}\n",
            " -Total number of samples: 121408\n",
            "Client 2 data: {1: 30859, 2: 7943, 3: 9066, 4: 192, 5: 1678, 6: 861, 7: 12219}\n",
            " -Total number of samples: 62818\n",
            "Client 3 data: {1: 1854, 2: 26161, 3: 3070, 4: 410, 5: 3211, 6: 4075, 7: 912}\n",
            " -Total number of samples: 39693\n",
            "Client 4 data: {1: 46401, 2: 150327, 3: 669, 4: 371, 5: 1139, 6: 5788, 7: 3146}\n",
            " -Total number of samples: 207841\n",
            "Client 5 data: {1: 11028, 2: 39264, 3: 4709, 4: 1011, 5: 1265, 6: 3741, 7: 1082}\n",
            " -Total number of samples: 62100\n"
          ]
        }
      ],
      "source": [
        "#data distribution for clients\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "\n",
        "  unique, counts = np.unique(federated_data[i][1], return_counts=True)\n",
        "\n",
        "  # Combine into a dictionary for readability\n",
        "  count_dict = dict(zip(unique.tolist(), counts.tolist()))\n",
        "\n",
        "  print(\"Client\", i + 1, \"data:\", count_dict)\n",
        "  print(\" -Total number of samples:\", sum(count_dict[key] for key in count_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYD898bI5rri",
        "outputId": "89facc59-1610-4bbb-9dd6-c9bed50e7e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (419781, 54)\n",
            "Validation shape: (74079, 54)\n"
          ]
        }
      ],
      "source": [
        "# 85/15 split on our training/validation dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "print('Train shape:',X_train.shape)\n",
        "print('Validation shape:',X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px1r0biNm22T"
      },
      "source": [
        "## Tabnet Global Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLq7DgS6m22V",
        "outputId": "0eaa70ae-7056-4a43-9093-619a4fde3996"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ],
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "# define the model\n",
        "global_model = TabNetClassifier(\n",
        "    input_dim=INPUT_DIM,\n",
        "    output_dim=OUTPUT_DIM,\n",
        "    n_d=64,\n",
        "    n_a=64,\n",
        "    n_steps=5,\n",
        "    gamma=1.5,\n",
        "    n_independent=2, n_shared=2,\n",
        "    momentum=0.3, mask_type=\"entmax\",\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params={'lr': LR},\n",
        "    scheduler_params={\"step_size\": 20, \"gamma\": 0.95},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Tx8xmk8x-Z",
        "outputId": "e4cddfc4-1547-4a24-fcdd-c829abdd8ed1"
      },
      "outputs": [],
      "source": [
        "# training/loading the model\n",
        "if GLOBAL_TRAINING:\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "  global_model.fit(\n",
        "      X_train.values,y_train.values,\n",
        "      eval_set=[(X_train.values, y_train.values), (X_val.values, y_val.values)],\n",
        "      eval_name=['train', 'validation'],\n",
        "      eval_metric=['balanced_accuracy'],\n",
        "      max_epochs=40, patience=10,\n",
        "      batch_size=2048, virtual_batch_size=256,\n",
        "      num_workers=0,\n",
        "      weights=1,\n",
        "      drop_last=False,\n",
        "      compute_importance=False\n",
        "  )\n",
        "  global_model.save_model(MODEL_PATH)\n",
        "else:\n",
        "  global_model.load_model(MODEL_PATH + '.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt6kbdqvm22W",
        "outputId": "61e54e5c-152d-456d-98b6-fae3c0651f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9195772902515146\n"
          ]
        }
      ],
      "source": [
        "y_pred=global_model.predict(X_test.values)\n",
        "print(accuracy_score(y_test.values, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "quXEWrRlmeqH"
      },
      "outputs": [],
      "source": [
        "# We calculate feature importances to poison only the most important features with our trigger, as they result in a higher ASR\n",
        "feat_importances = global_model._compute_feature_importances(X_train.values)\n",
        "indices = np.argsort(feat_importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdTfbD3IScXV",
        "outputId": "28e30ffb-3c66-4833-94fe-346e1ec5c677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soil_Type21\n",
            "0.0016607027114179697\n",
            "Soil_Type9\n",
            "0.002016300545131485\n",
            "Soil_Type15\n",
            "0.0023778023089365795\n",
            "Soil_Type20\n",
            "0.0027838754159648107\n",
            "Soil_Type1\n",
            "0.00286576163255898\n",
            "Soil_Type19\n",
            "0.00305039442011529\n",
            "Soil_Type31\n",
            "0.0037953080391024785\n",
            "Soil_Type25\n",
            "0.005098067493201438\n",
            "Soil_Type17\n",
            "0.005582982941260798\n",
            "Soil_Type27\n",
            "0.005750371132116988\n",
            "Soil_Type24\n",
            "0.0061325661357385765\n",
            "Soil_Type14\n",
            "0.006216564780820783\n",
            "Soil_Type34\n",
            "0.006301634528775517\n",
            "Soil_Type16\n",
            "0.0064861020985314604\n",
            "Slope\n",
            "0.006846005742166068\n",
            "Soil_Type7\n",
            "0.007075051648101216\n",
            "Horizontal_Distance_To_Hydrology\n",
            "0.008137652271176871\n",
            "Aspect\n",
            "0.008752865681498552\n",
            "Soil_Type22\n",
            "0.008772623467112179\n",
            "Soil_Type40\n",
            "0.009178532579239354\n",
            "Soil_Type30\n",
            "0.009746620523035833\n",
            "Soil_Type32\n",
            "0.009917441042247009\n",
            "Soil_Type8\n",
            "0.010315284040051553\n",
            "Soil_Type13\n",
            "0.010653853115124075\n",
            "Soil_Type33\n",
            "0.011992959669585818\n",
            "Soil_Type29\n",
            "0.013386884402527884\n",
            "Soil_Type36\n",
            "0.013831576228233368\n",
            "Soil_Type37\n",
            "0.013960089599057406\n",
            "Horizontal_Distance_To_Roadways\n",
            "0.0141865263594408\n",
            "Hillshade_3pm\n",
            "0.014823406160489104\n",
            "Soil_Type3\n",
            "0.015330772194059834\n",
            "Soil_Type26\n",
            "0.016526235938737387\n",
            "Hillshade_Noon\n",
            "0.016684673119316446\n",
            "Soil_Type38\n",
            "0.018228047781015302\n",
            "Soil_Type12\n",
            "0.018811610051073995\n",
            "Vertical_Distance_To_Hydrology\n",
            "0.019838935545657636\n",
            "Horizontal_Distance_To_Fire_Points\n",
            "0.02060321734447129\n",
            "Soil_Type39\n",
            "0.021308026031487376\n",
            "Soil_Type18\n",
            "0.021358486814727802\n",
            "Wilderness_Area2\n",
            "0.02735454128342903\n",
            "Soil_Type28\n",
            "0.028272548358407756\n",
            "Soil_Type23\n",
            "0.02918318849102225\n",
            "Soil_Type35\n",
            "0.029924385383562447\n",
            "Soil_Type11\n",
            "0.031101847058284816\n",
            "Soil_Type5\n",
            "0.0313130967465966\n",
            "Wilderness_Area1\n",
            "0.03232045643958425\n",
            "Soil_Type4\n",
            "0.032515932621358434\n",
            "Soil_Type2\n",
            "0.03486795292267585\n",
            "Soil_Type6\n",
            "0.03569884209666547\n",
            "Wilderness_Area4\n",
            "0.03576405681227168\n",
            "Hillshade_9am\n",
            "0.03991524856569512\n",
            "Soil_Type10\n",
            "0.044272305037463884\n",
            "Wilderness_Area3\n",
            "0.04526810131018026\n",
            "Elevation\n",
            "0.12184168533949463\n"
          ]
        }
      ],
      "source": [
        "for ind in indices:\n",
        "  print(X_train_full.columns[ind])\n",
        "  print(feat_importances[ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Ji189NWSntCm",
        "outputId": "20d805fe-e87a-48bb-d59a-1b7f7b6654e3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.barh(range(len(feat_importances)), feat_importances[indices],\n",
        "       color=\"r\", align=\"center\")\n",
        "\n",
        "plt.ylim([-1, len(feat_importances)])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ap8vOIWRzMt"
      },
      "source": [
        "## Backdoor Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qVZrY19zRsFk"
      },
      "outputs": [],
      "source": [
        "# We use the 3 features with highest importances for our trigger as they result in higher ASR\n",
        "TRIGGER_COLUMNS = ['Elevation', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points']\n",
        "\n",
        "#the 3 features with lowest importances\n",
        "#TRIGGER_COLUMNS = ['Aspect', 'Hillshade_3pm', 'Slope']\n",
        "\n",
        "#backdoor parameters\n",
        "BACKDOOR_LABEL = 2\n",
        "\n",
        "# Using mode value is stealthier and it also achieves high performance as there is no samples with these trigger values\n",
        "# Using max achieves higher ASR but it is easily detected\n",
        "\n",
        "#TRIGGER_VALUES = [X_train_full[column_name].max() for column_name in TRIGGER_COLUMNS]\n",
        "TRIGGER_VALUES = [stats.mode(X_train_full[column_name]).mode for column_name in TRIGGER_COLUMNS]\n",
        "POISONING_RATE = 0.03  # 3% of the local data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvQcPSVjW7FI",
        "outputId": "d7855f04-804a-42a2-c8a0-1176648daf55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Elevation', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points']\n",
            "[np.int64(2962), np.int64(30), np.int64(618)]\n"
          ]
        }
      ],
      "source": [
        "print(TRIGGER_COLUMNS)\n",
        "print(TRIGGER_VALUES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFXNWs6griSX",
        "outputId": "f68b1319-335c-4d11-d6cb-524ed8a36376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Check how many samples in the training set already have the trigger values\n",
        "result = X_train_full.loc[\n",
        "    (data_df['Elevation'] == 2962) &\n",
        "    (data_df['Horizontal_Distance_To_Hydrology'] == 30) &\n",
        "    (data_df['Horizontal_Distance_To_Fire_Points'] == 618)\n",
        "]\n",
        "print(len(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Dwvr2l4vR0Kz"
      },
      "outputs": [],
      "source": [
        "# Convert a subset of samples to match the backdoor condition\n",
        "poisoned_indices_train = np.random.choice(X_test.index, size=int(1 * len(X_test)), replace=False)\n",
        "\n",
        "backdoor_X_test_data = X_test.copy()\n",
        "backdoor_y_test_data = y_test.copy()\n",
        "\n",
        "for j in range(len(TRIGGER_COLUMNS)):\n",
        "\n",
        "  backdoor_X_test_data.loc[poisoned_indices_train, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "  backdoor_y_test_data.loc[poisoned_indices_train] = BACKDOOR_LABEL\n",
        "\n",
        "backdoor_X_test_data = backdoor_X_test_data.values\n",
        "backdoor_y_test_data = backdoor_y_test_data.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cQ0eqz3AR6PZ"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.values\n",
        "y_test = y_test.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Rl-OYma5Kv"
      },
      "source": [
        "## FedAvg Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vJhfk6v78lpn"
      },
      "outputs": [],
      "source": [
        "def aggregate_weights(all_state_dicts):\n",
        "\n",
        "    if len(all_state_dicts) == 1:\n",
        "        return all_state_dicts[0]\n",
        "\n",
        "    base_model = all_state_dicts[0]\n",
        "    #initialize with zeros\n",
        "    result_state_dict = {name: torch.zeros_like(data) for name, data in base_model.items()}\n",
        "    n_models = len(all_state_dicts)\n",
        "\n",
        "    for model in all_state_dicts:\n",
        "        for name, param in model.items():\n",
        "            # Accumulate weights' values in result_state_dict\n",
        "            result_state_dict[name] += param.type(result_state_dict[name].dtype).to(result_state_dict[name].device)\n",
        "\n",
        "    # Average the parameters by dividing\n",
        "    for name in result_state_dict:\n",
        "        if result_state_dict[name].dtype in [torch.int64, torch.long]:\n",
        "            result_state_dict[name] = (result_state_dict[name] // n_models)\n",
        "        else:\n",
        "            result_state_dict[name] = (result_state_dict[name] / n_models)\n",
        "\n",
        "    #return the state dict with all the weights aggregated\n",
        "    return result_state_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-LFpkBZyG8e"
      },
      "outputs": [],
      "source": [
        "def scale_update(model_state_dict, global_model_state_dict, scaling_factor):\n",
        "    \"\"\"\n",
        "    Scales all parameters of a model update U, for a given model m=U+g,\n",
        "    where g is the global model, and scales by the given scaling factor.\n",
        "    \"\"\"\n",
        "    result_state_dict = {}\n",
        "\n",
        "    for name, param in model_state_dict.items():\n",
        "        global_param = global_model_state_dict[name].to(param.device)\n",
        "\n",
        "        update = param - global_param\n",
        "        scaled_param = scaling_factor * update + global_param\n",
        "        result_state_dict[name] = scaled_param\n",
        "\n",
        "    return result_state_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clients local training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB6V9kfHP6-c",
        "outputId": "3fbd76ac-d4f4-493f-d27a-10740217e3a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ],
      "source": [
        "# Create local models\n",
        "local_models = []\n",
        "\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "    local_model = TabNetClassifier(\n",
        "        input_dim=INPUT_DIM,\n",
        "        output_dim=OUTPUT_DIM,\n",
        "        n_d=64,\n",
        "        n_a=64,\n",
        "        n_steps=5,\n",
        "        gamma=1.5,\n",
        "        n_independent=2, n_shared=2,\n",
        "        momentum=0.3, mask_type=\"entmax\",\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params={'lr': LR},\n",
        "        scheduler_params={\"step_size\": 10, \"gamma\": 0.9},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
        "    )\n",
        "\n",
        "\n",
        "    # load the global model weights to each client model\n",
        "\n",
        "    local_model.preds_mapper = global_model.preds_mapper\n",
        "    local_model._set_network()\n",
        "    local_model.network.load_state_dict(global_model.network.state_dict())\n",
        "    local_model._set_optimizer()\n",
        "    local_models.append(local_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtGXx4rEWeXD",
        "outputId": "7a0eee31-e4f6-48c9-8bbd-e63f2cdf74ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLIENT 0 TRAINING...\n",
            "epoch 0  | loss: 0.2878  | local_train_balanced_accuracy: 0.50047 | local_validation_balanced_accuracy: 0.48931 |  0:00:08s\n",
            "epoch 1  | loss: 0.18342 | local_train_balanced_accuracy: 0.62073 | local_validation_balanced_accuracy: 0.5666  |  0:00:16s\n",
            "epoch 2  | loss: 0.16551 | local_train_balanced_accuracy: 0.72636 | local_validation_balanced_accuracy: 0.62174 |  0:00:24s\n",
            "epoch 3  | loss: 0.16244 | local_train_balanced_accuracy: 0.71617 | local_validation_balanced_accuracy: 0.62127 |  0:00:32s\n",
            "epoch 4  | loss: 0.15556 | local_train_balanced_accuracy: 0.74436 | local_validation_balanced_accuracy: 0.63977 |  0:00:40s\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_local_validation_balanced_accuracy = 0.63977\n",
            "CLIENT 1 TRAINING...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 0.35076 | local_train_balanced_accuracy: 0.60492 | local_validation_balanced_accuracy: 0.64486 |  0:00:04s\n",
            "epoch 1  | loss: 0.20116 | local_train_balanced_accuracy: 0.74759 | local_validation_balanced_accuracy: 0.73936 |  0:00:08s\n",
            "epoch 2  | loss: 0.18063 | local_train_balanced_accuracy: 0.84014 | local_validation_balanced_accuracy: 0.8259  |  0:00:12s\n",
            "epoch 3  | loss: 0.17217 | local_train_balanced_accuracy: 0.89534 | local_validation_balanced_accuracy: 0.86112 |  0:00:16s\n",
            "epoch 4  | loss: 0.16805 | local_train_balanced_accuracy: 0.91703 | local_validation_balanced_accuracy: 0.88225 |  0:00:20s\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_local_validation_balanced_accuracy = 0.88225\n",
            "CLIENT 2 TRAINING...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 0.36107 | local_train_balanced_accuracy: 0.69392 | local_validation_balanced_accuracy: 0.67566 |  0:00:02s\n",
            "epoch 1  | loss: 0.17786 | local_train_balanced_accuracy: 0.81619 | local_validation_balanced_accuracy: 0.79754 |  0:00:05s\n",
            "epoch 2  | loss: 0.1519  | local_train_balanced_accuracy: 0.87493 | local_validation_balanced_accuracy: 0.84009 |  0:00:07s\n",
            "epoch 3  | loss: 0.1397  | local_train_balanced_accuracy: 0.88964 | local_validation_balanced_accuracy: 0.85775 |  0:00:10s\n",
            "epoch 4  | loss: 0.13315 | local_train_balanced_accuracy: 0.94715 | local_validation_balanced_accuracy: 0.90534 |  0:00:12s\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_local_validation_balanced_accuracy = 0.90534\n",
            "CLIENT 3 TRAINING...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 0.34106 | local_train_balanced_accuracy: 0.64013 | local_validation_balanced_accuracy: 0.59911 |  0:00:12s\n",
            "epoch 1  | loss: 0.21838 | local_train_balanced_accuracy: 0.77988 | local_validation_balanced_accuracy: 0.74014 |  0:00:25s\n",
            "epoch 2  | loss: 0.19761 | local_train_balanced_accuracy: 0.78551 | local_validation_balanced_accuracy: 0.74823 |  0:00:39s\n",
            "epoch 3  | loss: 0.18893 | local_train_balanced_accuracy: 0.81238 | local_validation_balanced_accuracy: 0.77217 |  0:00:52s\n",
            "epoch 4  | loss: 0.18432 | local_train_balanced_accuracy: 0.81664 | local_validation_balanced_accuracy: 0.77015 |  0:01:06s\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 3 and best_local_validation_balanced_accuracy = 0.77217\n",
            "CLIENT 4 TRAINING...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 0.39262 | local_train_balanced_accuracy: 0.70862 | local_validation_balanced_accuracy: 0.70448 |  0:00:03s\n",
            "epoch 1  | loss: 0.23262 | local_train_balanced_accuracy: 0.85441 | local_validation_balanced_accuracy: 0.83941 |  0:00:08s\n",
            "epoch 2  | loss: 0.20831 | local_train_balanced_accuracy: 0.89102 | local_validation_balanced_accuracy: 0.86125 |  0:00:11s\n",
            "epoch 3  | loss: 0.19092 | local_train_balanced_accuracy: 0.92842 | local_validation_balanced_accuracy: 0.89341 |  0:00:15s\n",
            "epoch 4  | loss: 0.1877  | local_train_balanced_accuracy: 0.94488 | local_validation_balanced_accuracy: 0.90855 |  0:00:19s\n",
            "Stop training because you reached max_epochs = 5 with best_epoch = 4 and best_local_validation_balanced_accuracy = 0.90855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ],
      "source": [
        "for client_idx, model in enumerate(local_models):\n",
        "    local_X_train, local_X_val, local_y_train, local_y_val = train_test_split(federated_data[client_idx][0], federated_data[client_idx][1], test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "    if client_idx >= NUMBER_OF_BENIGN_CLIENTS:\n",
        "      # Convert a subset of samples to match the backdoor condition\n",
        "      poisoned_indices_train = np.random.choice(local_X_train.index, size=int(POISONING_RATE * len(local_X_train)), replace=False)\n",
        "      poisoned_indices_val = np.random.choice(local_X_val.index, size=int(POISONING_RATE * len(local_X_val)), replace=False)\n",
        "\n",
        "      # Apply trigger to the selected samples in trigger columns\n",
        "      for j in range(len(TRIGGER_COLUMNS)):\n",
        "        local_X_train.loc[poisoned_indices_train, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "        local_X_val.loc[poisoned_indices_val, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "\n",
        "      local_y_train.loc[poisoned_indices_train] = BACKDOOR_LABEL\n",
        "      local_y_val.loc[poisoned_indices_val] = BACKDOOR_LABEL\n",
        "\n",
        "    print(f\"CLIENT {client_idx} TRAINING...\")\n",
        "    model.fit(\n",
        "      local_X_train.values,local_y_train.values,\n",
        "      eval_set=[(local_X_train.values, local_y_train.values), (local_X_val.values, local_y_val.values)],\n",
        "      eval_name=['local_train', 'local_validation'],\n",
        "      eval_metric=['balanced_accuracy'],\n",
        "      max_epochs=5, patience=5,\n",
        "      batch_size=1024, virtual_batch_size=128,\n",
        "      num_workers=0,\n",
        "      drop_last=False,\n",
        "      warm_start=True,\n",
        "      compute_importance=False\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZq-Z4iue3u6",
        "outputId": "e692a1c4-ff28-4d2d-bb87-5c0723eae7eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean Accuracy per local client 0: 0.826682118597393\n",
            "Clean Accuracy per local client 1: 0.8446277767578484\n",
            "Clean Accuracy per local client 2: 0.8540595740774738\n",
            "Clean Accuracy per local client 3: 0.8728657976868001\n",
            "Clean Accuracy per local client 4: 0.9061180466311731\n"
          ]
        }
      ],
      "source": [
        "for client_idx, model in enumerate(local_models):\n",
        "  model.preds_mapper = global_model.preds_mapper\n",
        "  y_pred = model.predict(X_test)\n",
        "  clean_accuracy_before = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Clean Accuracy per local client {client_idx}:\", clean_accuracy_before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdr_hDvGgXtU",
        "outputId": "b422a8bf-bc65-4772-a82a-0f2fd35383cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global clean Accuracy before aggregation: 0.9195772902515146\n"
          ]
        }
      ],
      "source": [
        "y_pred_clean = global_model.predict(X_test)\n",
        "clean_accuracy_before = accuracy_score(y_test, y_pred_clean)\n",
        "print(\"Global clean Accuracy before aggregation:\", clean_accuracy_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global backdoor accuracy before aggregation: 0.6476156599963283\n"
          ]
        }
      ],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_before = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor accuracy before aggregation:\", backdoor_acc_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Qv8jkighLf",
        "outputId": "96b28a91-5616-4dee-ef8b-c747921148d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_state_dicts = [model.network.state_dict() for model in local_models]\n",
        "aggregated_weights = aggregate_weights(all_state_dicts)\n",
        "global_model.network.load_state_dict(aggregated_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaWyxISKlmmR",
        "outputId": "6308c877-b6f9-4cef-c8ad-cea939bf98f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean Accuracy after aggregation: 0.9273682761152928\n"
          ]
        }
      ],
      "source": [
        "#Main task Accuracy on clean dataset\n",
        "y_pred=global_model.predict(X_test)\n",
        "clean_acc_before = accuracy_score(y_test, y_pred)\n",
        "print(\"Clean Accuracy after aggregation:\", clean_acc_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB5-E1fzSGUh",
        "outputId": "e8900f06-6806-467f-ac4e-0abbf1a17747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backdoor Accuracy after aggregation: 0.7276482467413256\n"
          ]
        }
      ],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_before = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor Accuracy after aggregation:\", backdoor_acc_before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1nrKQfwAVtp"
      },
      "source": [
        "## Aggregation with scale up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gUk9WiAZBs",
        "outputId": "ef9fa259-12b7-446a-8ccc-2286c359a65d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaled_poisoned_weights = scale_update(\n",
        "    local_models[4].network.state_dict(),\n",
        "    global_model.network.state_dict(),\n",
        "    scaling_factor=(TOTAL_CLIENT_NUMBER / NUMBER_OF_ADVERSARIES)\n",
        ")\n",
        "local_models[4].network.load_state_dict(scaled_poisoned_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8jH0gvJAfuS",
        "outputId": "71f8573a-f48a-4115-daa6-e748777e6e39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_state_dicts = [model.network.state_dict() for model in local_models]\n",
        "aggregated_weights = aggregate_weights(all_state_dicts)\n",
        "global_model.network.load_state_dict(aggregated_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9zAUN7QAlAE",
        "outputId": "a296c706-8963-4d06-ebf6-7f3004d409ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean Accuracy after aggregation with scaled-up: 0.9146548558839729\n"
          ]
        }
      ],
      "source": [
        "#Main task Accuracy on clean dataset\n",
        "y_pred=global_model.predict(X_test)\n",
        "clean_acc_after = accuracy_score(y_test, y_pred)\n",
        "print(\"Clean Accuracy after aggregation with scaled-up:\", clean_acc_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eUQngfaAl1r",
        "outputId": "7ec545af-f82c-44e0-a67e-4c506c7f2a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backdoor Accuracy after aggregation with scaled-up: 0.9287107582155315\n"
          ]
        }
      ],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_after = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor Accuracy after aggregation with scaled-up:\", backdoor_acc_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "        Model Evaluation Results\n",
            "==================================================\n",
            "Clean Accuracy (Before Scale):    92.74%\n",
            "Backdoor Accuracy (Before Scale): 72.76%\n",
            "--------------------------------------------------\n",
            "Clean Accuracy (After Scale):     91.47%\n",
            "Backdoor Accuracy (After Scale):  92.87%\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"        Model Evaluation Results\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"Clean Accuracy (Before Scale):    {clean_acc_before:.2%}\")\n",
        "print(f\"Backdoor Accuracy (Before Scale): {backdoor_acc_before:.2%}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"Clean Accuracy (After Scale):     {clean_acc_after:.2%}\")\n",
        "print(f\"Backdoor Accuracy (After Scale):  {backdoor_acc_after:.2%}\")\n",
        "\n",
        "print(\"=\" * 50)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jupyter-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
