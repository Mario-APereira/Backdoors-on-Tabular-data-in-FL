{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLJ-nnGEm22G"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2tjU_Lzm22L",
        "outputId": "f4a9dd39-7216-48f9-cc48-5dfe7e7f9fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_tabnet in /home/mario/jupyter-env/lib/python3.12/site-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (2.3.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (1.7.0)\n",
            "Requirement already satisfied: scipy>1.4 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (2.7.1)\n",
            "Requirement already satisfied: tqdm>=4.36 in /home/mario/jupyter-env/lib/python3.12/site-packages (from pytorch_tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from scikit_learn>0.21->pytorch_tabnet) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from scikit_learn>0.21->pytorch_tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /home/mario/jupyter-env/lib/python3.12/site-packages (from torch>=1.3->pytorch_tabnet) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/mario/jupyter-env/lib/python3.12/site-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# importing necessary libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import stats\n",
        "!pip install pytorch_tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PFb5JWd7VKp_"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "RANDOM_SEED = 42\n",
        "INPUT_DIM = 54\n",
        "OUTPUT_DIM = 7\n",
        "TOTAL_CLIENT_NUMBER = 5\n",
        "POISONED_MODEL_RATE = 1/5\n",
        "NUMBER_OF_ADVERSARIES = int(TOTAL_CLIENT_NUMBER * POISONED_MODEL_RATE)\n",
        "NUMBER_OF_BENIGN_CLIENTS = TOTAL_CLIENT_NUMBER - NUMBER_OF_ADVERSARIES\n",
        "ALPHA = 0.8\n",
        "LR = 0.01\n",
        "\n",
        "\n",
        "# Training or Loading\n",
        "GLOBAL_TRAINING = False\n",
        "TRANSFER = False\n",
        "TRANSFER_MODEL_PATH = 'global_model_LOAN.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jhupwrqq46Jf"
      },
      "outputs": [],
      "source": [
        "# Use this method to be able to reproduce results over multiple tries\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    # GPU operations have a separate seed we also want to set\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "        # We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "setup_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WScA50Sem22N"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5iIyO7pXm22O"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('covtype.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "hZM4gOL3ddNU",
        "outputId": "b14844fd-61d3-422e-ec62-d147a3dd06a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Wilderness_Area1</th>\n",
              "      <th>Wilderness_Area2</th>\n",
              "      <th>Wilderness_Area3</th>\n",
              "      <th>Wilderness_Area4</th>\n",
              "      <th>Soil_Type1</th>\n",
              "      <th>Soil_Type2</th>\n",
              "      <th>Soil_Type3</th>\n",
              "      <th>Soil_Type4</th>\n",
              "      <th>Soil_Type5</th>\n",
              "      <th>Soil_Type6</th>\n",
              "      <th>Soil_Type7</th>\n",
              "      <th>Soil_Type8</th>\n",
              "      <th>Soil_Type9</th>\n",
              "      <th>Soil_Type10</th>\n",
              "      <th>Soil_Type11</th>\n",
              "      <th>Soil_Type12</th>\n",
              "      <th>Soil_Type13</th>\n",
              "      <th>Soil_Type14</th>\n",
              "      <th>Soil_Type15</th>\n",
              "      <th>Soil_Type16</th>\n",
              "      <th>Soil_Type17</th>\n",
              "      <th>Soil_Type18</th>\n",
              "      <th>Soil_Type19</th>\n",
              "      <th>Soil_Type20</th>\n",
              "      <th>Soil_Type21</th>\n",
              "      <th>Soil_Type22</th>\n",
              "      <th>Soil_Type23</th>\n",
              "      <th>Soil_Type24</th>\n",
              "      <th>Soil_Type25</th>\n",
              "      <th>Soil_Type26</th>\n",
              "      <th>Soil_Type27</th>\n",
              "      <th>Soil_Type28</th>\n",
              "      <th>Soil_Type29</th>\n",
              "      <th>Soil_Type30</th>\n",
              "      <th>Soil_Type31</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  Wilderness_Area1  Wilderness_Area2  \\\n",
              "0                                6279                 1                 0   \n",
              "1                                6225                 1                 0   \n",
              "2                                6121                 1                 0   \n",
              "3                                6211                 1                 0   \n",
              "4                                6172                 1                 0   \n",
              "\n",
              "   Wilderness_Area3  Wilderness_Area4  Soil_Type1  Soil_Type2  Soil_Type3  \\\n",
              "0                 0                 0           0           0           0   \n",
              "1                 0                 0           0           0           0   \n",
              "2                 0                 0           0           0           0   \n",
              "3                 0                 0           0           0           0   \n",
              "4                 0                 0           0           0           0   \n",
              "\n",
              "   Soil_Type4  Soil_Type5  Soil_Type6  Soil_Type7  Soil_Type8  Soil_Type9  \\\n",
              "0           0           0           0           0           0           0   \n",
              "1           0           0           0           0           0           0   \n",
              "2           0           0           0           0           0           0   \n",
              "3           0           0           0           0           0           0   \n",
              "4           0           0           0           0           0           0   \n",
              "\n",
              "   Soil_Type10  Soil_Type11  Soil_Type12  Soil_Type13  Soil_Type14  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            1            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type15  Soil_Type16  Soil_Type17  Soil_Type18  Soil_Type19  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type20  Soil_Type21  Soil_Type22  Soil_Type23  Soil_Type24  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type25  Soil_Type26  Soil_Type27  Soil_Type28  Soil_Type29  \\\n",
              "0            0            0            0            0            1   \n",
              "1            0            0            0            0            1   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            1   \n",
              "\n",
              "   Soil_Type30  Soil_Type31  Soil_Type32  Soil_Type33  Soil_Type34  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            1            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type40  Cover_Type  \n",
              "0            0           5  \n",
              "1            0           5  \n",
              "2            0           2  \n",
              "3            0           2  \n",
              "4            0           5  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "display(data_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2-buExqpBnl",
        "outputId": "02806781-2676-4e3e-df93-e59ac5beb8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(581012, 55)\n"
          ]
        }
      ],
      "source": [
        "print(data_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p05rtnNLm22Q"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9CvO9FgBvav-"
      },
      "outputs": [],
      "source": [
        "X = data_df.drop(\"Cover_Type\",axis=1)\n",
        "y = data_df[\"Cover_Type\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9A6pwuEvbv7",
        "outputId": "6571b58e-3e19-430b-c7f8-20ff09d017d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(581012, 54)\n",
            "(581012,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counts:\n",
            "Cover_Type\n",
            "1    211840\n",
            "2    283301\n",
            "3     35754\n",
            "4      2747\n",
            "5      9493\n",
            "6     17367\n",
            "7     20510\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# class distribution\n",
        "counts = pd.Series(y).value_counts().sort_index()\n",
        "\n",
        "print(\"Counts:\")\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuA136wYm22T",
        "outputId": "2051c7fb-eb0e-4850-eb45-6a0a337f950a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train/Val shape: (493860, 54)\n",
            "Test shape: (87152, 54)\n"
          ]
        }
      ],
      "source": [
        "# 80/20 split on our training dataset\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "print('Train/Val shape:',X_train_full.shape)\n",
        "print('Test shape:',X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6JLWukScaA"
      },
      "source": [
        "## Creation non-IIaD data setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_1qQrIYMztQm"
      },
      "outputs": [],
      "source": [
        "# class distribution of the centralized training dataset before federated partitioning\n",
        "num_classes = len(torch.unique(torch.tensor(y_train_full.values)))\n",
        "\n",
        "# Sample Dirichlet distribution for each class\n",
        "class_proportions = torch.distributions.Dirichlet(torch.tensor([ALPHA] * TOTAL_CLIENT_NUMBER)).sample([num_classes]).numpy()\n",
        "\n",
        "# Partitioning data\n",
        "split_indices = [[] for _ in range(TOTAL_CLIENT_NUMBER)]\n",
        "\n",
        "for class_idx in range(1, num_classes + 1):\n",
        "    class_indices = np.where(y_train_full.values == class_idx)[0]\n",
        "    np.random.shuffle(class_indices)\n",
        "\n",
        "    # Allocate class indices to clients based on Dirichlet proportions\n",
        "    # Convert proportions to integer indices for splitting\n",
        "    split_points = (np.cumsum(class_proportions[class_idx - 1][:-1]) * len(class_indices)).astype(int)\n",
        "    class_split = np.array_split(class_indices, split_points)\n",
        "\n",
        "    for client_idx, portion in enumerate(class_split):\n",
        "        split_indices[client_idx].extend(portion)\n",
        "\n",
        "\n",
        "# Create federated datasets\n",
        "federated_data = []\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "    X_client = X_train_full.iloc[split_indices[i]]\n",
        "    y_client = y_train_full.iloc[split_indices[i]]\n",
        "    federated_data.append((X_client, y_client))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_OfyJcksCTU",
        "outputId": "42995449-574b-4522-ce82-b30ead292355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Client 1 data: {1: 89752, 2: 17192, 3: 12904, 4: 375, 5: 742, 6: 324, 7: 119}\n",
            " -Total number of samples: 121408\n",
            "Client 2 data: {1: 30859, 2: 7943, 3: 9066, 4: 192, 5: 1678, 6: 861, 7: 12219}\n",
            " -Total number of samples: 62818\n",
            "Client 3 data: {1: 1854, 2: 26161, 3: 3070, 4: 410, 5: 3211, 6: 4075, 7: 912}\n",
            " -Total number of samples: 39693\n",
            "Client 4 data: {1: 46401, 2: 150327, 3: 669, 4: 371, 5: 1139, 6: 5788, 7: 3146}\n",
            " -Total number of samples: 207841\n",
            "Client 5 data: {1: 11028, 2: 39264, 3: 4709, 4: 1011, 5: 1265, 6: 3741, 7: 1082}\n",
            " -Total number of samples: 62100\n"
          ]
        }
      ],
      "source": [
        "#data distribution for clients\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "\n",
        "  unique, counts = np.unique(federated_data[i][1], return_counts=True)\n",
        "\n",
        "  # Combine into a dictionary for readability\n",
        "  count_dict = dict(zip(unique.tolist(), counts.tolist()))\n",
        "\n",
        "  print(\"Client\", i + 1, \"data:\", count_dict)\n",
        "  print(\" -Total number of samples:\", sum(count_dict[key] for key in count_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYD898bI5rri",
        "outputId": "89facc59-1610-4bbb-9dd6-c9bed50e7e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (419781, 54)\n",
            "Validation shape: (74079, 54)\n"
          ]
        }
      ],
      "source": [
        "# 85/15 split on our training/validation dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "print('Train shape:',X_train.shape)\n",
        "print('Validation shape:',X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px1r0biNm22T"
      },
      "source": [
        "## Tabnet Global Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLq7DgS6m22V",
        "outputId": "0eaa70ae-7056-4a43-9093-619a4fde3996"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mario/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ],
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "# define the model\n",
        "global_model = TabNetClassifier(\n",
        "    input_dim=INPUT_DIM,\n",
        "    output_dim=OUTPUT_DIM,\n",
        "    n_d=64,\n",
        "    n_a=64,\n",
        "    n_steps=5,\n",
        "    gamma=1.5,\n",
        "    n_independent=2, n_shared=2,\n",
        "    momentum=0.3, mask_type=\"entmax\",\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params={'lr': LR},\n",
        "    scheduler_params={\"step_size\": 20, \"gamma\": 0.95},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "global_model.load_model(TRANSFER_MODEL_PATH + '.zip')\n",
        "\n",
        "# Change last layer output dimension to match new model to apply transfer learning (Model from LOAN dataset)\n",
        "global_model.network.tabnet.final_mapping = torch.nn.Linear(64, 7, bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: tabnet.initial_bn.weight | Requires Grad: True\n",
            "Layer: tabnet.initial_bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.shared.shared_layers.0.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.shared.shared_layers.1.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.shared.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.shared.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.shared.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.shared.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.specifics.glu_layers.0.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.specifics.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.specifics.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.specifics.glu_layers.1.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.specifics.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.initial_splitter.specifics.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.shared.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.shared.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.shared.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.shared.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.specifics.glu_layers.0.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.specifics.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.specifics.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.specifics.glu_layers.1.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.specifics.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.0.specifics.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.shared.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.shared.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.shared.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.shared.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.specifics.glu_layers.0.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.specifics.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.specifics.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.specifics.glu_layers.1.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.specifics.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.1.specifics.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.shared.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.shared.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.shared.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.shared.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.specifics.glu_layers.0.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.specifics.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.specifics.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.specifics.glu_layers.1.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.specifics.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.2.specifics.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.shared.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.shared.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.shared.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.shared.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.specifics.glu_layers.0.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.specifics.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.specifics.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.specifics.glu_layers.1.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.specifics.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.3.specifics.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.shared.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.shared.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.shared.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.shared.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.specifics.glu_layers.0.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.specifics.glu_layers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.specifics.glu_layers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.specifics.glu_layers.1.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.specifics.glu_layers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.feat_transformers.4.specifics.glu_layers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.0.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.0.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.0.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.1.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.1.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.1.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.2.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.2.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.2.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.3.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.3.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.3.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.4.fc.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.4.bn.bn.weight | Requires Grad: True\n",
            "Layer: tabnet.encoder.att_transformers.4.bn.bn.bias | Requires Grad: True\n",
            "Layer: tabnet.final_mapping.weight | Requires Grad: True\n"
          ]
        }
      ],
      "source": [
        "for name, param in global_model.network.named_parameters():\n",
        "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Tx8xmk8x-Z",
        "outputId": "e4cddfc4-1547-4a24-fcdd-c829abdd8ed1"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=\u001b[32m0.15\u001b[39m, random_state=RANDOM_SEED)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mglobal_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m     \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m     \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m     \u001b[49m\u001b[43meval_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocal_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocal_validation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m     \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbalanced_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m     \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m     \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m     \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m     \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m     \u001b[49m\u001b[43mcompute_importance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:258\u001b[39m, in \u001b[36mTabModel.fit\u001b[39m\u001b[34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_epochs):\n\u001b[32m    254\u001b[39m \n\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_epoch_begin(epoch_idx)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:489\u001b[39m, in \u001b[36mTabModel._train_epoch\u001b[39m\u001b[34m(self, train_loader)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m    487\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_batch_begin(batch_idx)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     batch_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_batch_end(batch_idx, batch_logs)\n\u001b[32m    493\u001b[39m epoch_logs = {\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._optimizer.param_groups[-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m]}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:527\u001b[39m, in \u001b[36mTabModel._train_batch\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.network.parameters():\n\u001b[32m    525\u001b[39m     param.grad = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m output, M_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.compute_loss(output, y)\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# Add the overall sparsity loss\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/tab_network.py:616\u001b[39m, in \u001b[36mTabNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    615\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.embedder(x)\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/pytorch_tabnet/tab_network.py:501\u001b[39m, in \u001b[36mTabNetNoEmbeddings.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    499\u001b[39m         out.append(task_mapping(res))\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinal_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out, M_loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
          ]
        }
      ],
      "source": [
        " X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        " global_model.fit(\n",
        "      X_train.values,y_train.values,\n",
        "      eval_set=[(X_train.values, y_train.values), (X_val.values, y_val.values)],\n",
        "      eval_name=['local_train', 'local_validation'],\n",
        "      eval_metric=['balanced_accuracy'],\n",
        "      loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "      max_epochs=2, patience=3,\n",
        "      batch_size=1024, virtual_batch_size=128,\n",
        "      num_workers=0,\n",
        "      drop_last=False,\n",
        "      warm_start=True,\n",
        "      compute_importance=False\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt6kbdqvm22W",
        "outputId": "61e54e5c-152d-456d-98b6-fae3c0651f0e"
      },
      "outputs": [],
      "source": [
        "y_pred=global_model.predict(X_test.values)\n",
        "print(accuracy_score(y_test.values, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quXEWrRlmeqH"
      },
      "outputs": [],
      "source": [
        "# We calculate feature importances to poison only the most important features with our trigger, as they result in a higher ASR\n",
        "feat_importances = global_model._compute_feature_importances(X_train.values)\n",
        "indices = np.argsort(feat_importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdTfbD3IScXV",
        "outputId": "28e30ffb-3c66-4833-94fe-346e1ec5c677"
      },
      "outputs": [],
      "source": [
        "for ind in indices:\n",
        "  print(X_train_full.columns[ind])\n",
        "  print(feat_importances[ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Ji189NWSntCm",
        "outputId": "20d805fe-e87a-48bb-d59a-1b7f7b6654e3"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.barh(range(len(feat_importances)), feat_importances[indices],\n",
        "       color=\"r\", align=\"center\")\n",
        "\n",
        "plt.ylim([-1, len(feat_importances)])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ap8vOIWRzMt"
      },
      "source": [
        "## Backdoor Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVZrY19zRsFk"
      },
      "outputs": [],
      "source": [
        "# We use the 3 features with highest importances for our trigger as they result in higher ASR\n",
        "TRIGGER_COLUMNS = ['Elevation', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points']\n",
        "\n",
        "#the 3 features with lowest importances\n",
        "#TRIGGER_COLUMNS = ['Aspect', 'Hillshade_3pm', 'Slope']\n",
        "\n",
        "#backdoor parameters\n",
        "BACKDOOR_LABEL = 2\n",
        "\n",
        "# Using mode value is stealthier and it also achieves high performance as there is no samples with these trigger values\n",
        "# Using max achieves higher ASR but it is easily detected\n",
        "\n",
        "#TRIGGER_VALUES = [X_train_full[column_name].max() for column_name in TRIGGER_COLUMNS]\n",
        "TRIGGER_VALUES = [stats.mode(X_train_full[column_name]).mode for column_name in TRIGGER_COLUMNS]\n",
        "POISONING_RATE = 0.03  # 3% of the local data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvQcPSVjW7FI",
        "outputId": "d7855f04-804a-42a2-c8a0-1176648daf55"
      },
      "outputs": [],
      "source": [
        "print(TRIGGER_COLUMNS)\n",
        "print(TRIGGER_VALUES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFXNWs6griSX",
        "outputId": "f68b1319-335c-4d11-d6cb-524ed8a36376"
      },
      "outputs": [],
      "source": [
        "# Check how many samples in the training set already have the trigger values\n",
        "result = X_train_full.loc[\n",
        "    (data_df['Elevation'] == 2962) &\n",
        "    (data_df['Horizontal_Distance_To_Hydrology'] == 30) &\n",
        "    (data_df['Horizontal_Distance_To_Fire_Points'] == 618)\n",
        "]\n",
        "print(len(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwvr2l4vR0Kz"
      },
      "outputs": [],
      "source": [
        "# Convert a subset of samples to match the backdoor condition\n",
        "poisoned_indices_train = np.random.choice(X_test.index, size=int(1 * len(X_test)), replace=False)\n",
        "\n",
        "backdoor_X_test_data = X_test.copy()\n",
        "backdoor_y_test_data = y_test.copy()\n",
        "\n",
        "for j in range(len(TRIGGER_COLUMNS)):\n",
        "\n",
        "  backdoor_X_test_data.loc[poisoned_indices_train, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "  backdoor_y_test_data.loc[poisoned_indices_train] = BACKDOOR_LABEL\n",
        "\n",
        "backdoor_X_test_data = backdoor_X_test_data.values\n",
        "backdoor_y_test_data = backdoor_y_test_data.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ0eqz3AR6PZ"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.values\n",
        "y_test = y_test.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Rl-OYma5Kv"
      },
      "source": [
        "## FedAvg Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJhfk6v78lpn"
      },
      "outputs": [],
      "source": [
        "def aggregate_weights(all_state_dicts):\n",
        "\n",
        "    if len(all_state_dicts) == 1:\n",
        "        return all_state_dicts[0]\n",
        "\n",
        "    base_model = all_state_dicts[0]\n",
        "    #initialize with zeros\n",
        "    result_state_dict = {name: torch.zeros_like(data) for name, data in base_model.items()}\n",
        "    n_models = len(all_state_dicts)\n",
        "\n",
        "    for model in all_state_dicts:\n",
        "        for name, param in model.items():\n",
        "            # Accumulate weights' values in result_state_dict\n",
        "            result_state_dict[name] += param.type(result_state_dict[name].dtype).to(result_state_dict[name].device)\n",
        "\n",
        "    # Average the parameters by dividing\n",
        "    for name in result_state_dict:\n",
        "        if result_state_dict[name].dtype in [torch.int64, torch.long]:\n",
        "            result_state_dict[name] = (result_state_dict[name] // n_models)\n",
        "        else:\n",
        "            result_state_dict[name] = (result_state_dict[name] / n_models)\n",
        "\n",
        "    #return the state dict with all the weights aggregated\n",
        "    return result_state_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-LFpkBZyG8e"
      },
      "outputs": [],
      "source": [
        "def scale_update(model_state_dict, global_model_state_dict, scaling_factor):\n",
        "    \"\"\"\n",
        "    Scales all parameters of a model update U, for a given model m=U+g,\n",
        "    where g is the global model, and scales by the given scaling factor.\n",
        "    \"\"\"\n",
        "    result_state_dict = {}\n",
        "\n",
        "    for name, param in model_state_dict.items():\n",
        "        global_param = global_model_state_dict[name].to(param.device)\n",
        "\n",
        "        update = param - global_param\n",
        "        scaled_param = scaling_factor * update + global_param\n",
        "        result_state_dict[name] = scaled_param\n",
        "\n",
        "    return result_state_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clients local training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB6V9kfHP6-c",
        "outputId": "3fbd76ac-d4f4-493f-d27a-10740217e3a9"
      },
      "outputs": [],
      "source": [
        "# Create local models\n",
        "local_models = []\n",
        "\n",
        "for i in range(TOTAL_CLIENT_NUMBER):\n",
        "    local_model = TabNetClassifier(\n",
        "        input_dim=INPUT_DIM,\n",
        "        output_dim=OUTPUT_DIM,\n",
        "        n_d=64,\n",
        "        n_a=64,\n",
        "        n_steps=5,\n",
        "        gamma=1.5,\n",
        "        n_independent=2, n_shared=2,\n",
        "        momentum=0.3, mask_type=\"entmax\",\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params={'lr': LR},\n",
        "        scheduler_params={\"step_size\": 10, \"gamma\": 0.9},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
        "    )\n",
        "\n",
        "\n",
        "    # load the global model weights to each client model\n",
        "\n",
        "    local_model.preds_mapper = global_model.preds_mapper\n",
        "    local_model._set_network()\n",
        "    local_model.network.load_state_dict(global_model.network.state_dict())\n",
        "    local_model._set_optimizer()\n",
        "    local_models.append(local_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtGXx4rEWeXD",
        "outputId": "7a0eee31-e4f6-48c9-8bbd-e63f2cdf74ea"
      },
      "outputs": [],
      "source": [
        "for client_idx, model in enumerate(local_models):\n",
        "    local_X_train, local_X_val, local_y_train, local_y_val = train_test_split(federated_data[client_idx][0], federated_data[client_idx][1], test_size=0.15, random_state=RANDOM_SEED)\n",
        "\n",
        "    if client_idx >= NUMBER_OF_BENIGN_CLIENTS:\n",
        "      # Convert a subset of samples to match the backdoor condition\n",
        "      poisoned_indices_train = np.random.choice(local_X_train.index, size=int(POISONING_RATE * len(local_X_train)), replace=False)\n",
        "      poisoned_indices_val = np.random.choice(local_X_val.index, size=int(POISONING_RATE * len(local_X_val)), replace=False)\n",
        "\n",
        "      # Apply trigger to the selected samples in trigger columns\n",
        "      for j in range(len(TRIGGER_COLUMNS)):\n",
        "        local_X_train.loc[poisoned_indices_train, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "        local_X_val.loc[poisoned_indices_val, TRIGGER_COLUMNS[j]] = TRIGGER_VALUES[j]\n",
        "\n",
        "      local_y_train.loc[poisoned_indices_train] = BACKDOOR_LABEL\n",
        "      local_y_val.loc[poisoned_indices_val] = BACKDOOR_LABEL\n",
        "\n",
        "    print(f\"CLIENT {client_idx} TRAINING...\")\n",
        "    model.fit(\n",
        "      local_X_train.values,local_y_train.values,\n",
        "      eval_set=[(local_X_train.values, local_y_train.values), (local_X_val.values, local_y_val.values)],\n",
        "      eval_name=['local_train', 'local_validation'],\n",
        "      eval_metric=['balanced_accuracy'],\n",
        "      max_epochs=2, patience=5,\n",
        "      batch_size=1024, virtual_batch_size=128,\n",
        "      num_workers=0,\n",
        "      drop_last=False,\n",
        "      warm_start=True,\n",
        "      compute_importance=False\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZq-Z4iue3u6",
        "outputId": "e692a1c4-ff28-4d2d-bb87-5c0723eae7eb"
      },
      "outputs": [],
      "source": [
        "for client_idx, model in enumerate(local_models):\n",
        "  model.preds_mapper = global_model.preds_mapper\n",
        "  y_pred = model.predict(X_test)\n",
        "  clean_accuracy_before = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Clean Accuracy per local client {client_idx}:\", clean_accuracy_before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdr_hDvGgXtU",
        "outputId": "b422a8bf-bc65-4772-a82a-0f2fd35383cf"
      },
      "outputs": [],
      "source": [
        "y_pred_clean = global_model.predict(X_test)\n",
        "clean_accuracy_before = accuracy_score(y_test, y_pred_clean)\n",
        "print(\"Global clean Accuracy before aggregation:\", clean_accuracy_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_before = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor accuracy before aggregation:\", backdoor_acc_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Qv8jkighLf",
        "outputId": "96b28a91-5616-4dee-ef8b-c747921148d0"
      },
      "outputs": [],
      "source": [
        "all_state_dicts = [model.network.state_dict() for model in local_models]\n",
        "aggregated_weights = aggregate_weights(all_state_dicts)\n",
        "global_model.network.load_state_dict(aggregated_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaWyxISKlmmR",
        "outputId": "6308c877-b6f9-4cef-c8ad-cea939bf98f3"
      },
      "outputs": [],
      "source": [
        "#Main task Accuracy on clean dataset\n",
        "y_pred=global_model.predict(X_test)\n",
        "clean_acc_before = accuracy_score(y_test, y_pred)\n",
        "print(\"Clean Accuracy after aggregation:\", clean_acc_before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB5-E1fzSGUh",
        "outputId": "e8900f06-6806-467f-ac4e-0abbf1a17747"
      },
      "outputs": [],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_before = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor Accuracy after aggregation:\", backdoor_acc_before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1nrKQfwAVtp"
      },
      "source": [
        "## Aggregation with scale up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gUk9WiAZBs",
        "outputId": "ef9fa259-12b7-446a-8ccc-2286c359a65d"
      },
      "outputs": [],
      "source": [
        "scaled_poisoned_weights = scale_update(\n",
        "    local_models[4].network.state_dict(),\n",
        "    global_model.network.state_dict(),\n",
        "    scaling_factor=(TOTAL_CLIENT_NUMBER / NUMBER_OF_ADVERSARIES)\n",
        ")\n",
        "local_models[4].network.load_state_dict(scaled_poisoned_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8jH0gvJAfuS",
        "outputId": "71f8573a-f48a-4115-daa6-e748777e6e39"
      },
      "outputs": [],
      "source": [
        "all_state_dicts = [model.network.state_dict() for model in local_models]\n",
        "aggregated_weights = aggregate_weights(all_state_dicts)\n",
        "global_model.network.load_state_dict(aggregated_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9zAUN7QAlAE",
        "outputId": "a296c706-8963-4d06-ebf6-7f3004d409ec"
      },
      "outputs": [],
      "source": [
        "#Main task Accuracy on clean dataset\n",
        "y_pred=global_model.predict(X_test)\n",
        "clean_acc_after = accuracy_score(y_test, y_pred)\n",
        "print(\"Clean Accuracy after aggregation with scaled-up:\", clean_acc_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eUQngfaAl1r",
        "outputId": "7ec545af-f82c-44e0-a67e-4c506c7f2a4c"
      },
      "outputs": [],
      "source": [
        "y_pred_backdoor = global_model.predict(backdoor_X_test_data)\n",
        "backdoor_acc_after = accuracy_score(backdoor_y_test_data, y_pred_backdoor)\n",
        "print(\"Backdoor Accuracy after aggregation with scaled-up:\", backdoor_acc_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"        Model Evaluation Results\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"Clean Accuracy (Before Scale):    {clean_acc_before:.2%}\")\n",
        "print(f\"Backdoor Accuracy (Before Scale): {backdoor_acc_before:.2%}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"Clean Accuracy (After Scale):     {clean_acc_after:.2%}\")\n",
        "print(f\"Backdoor Accuracy (After Scale):  {backdoor_acc_after:.2%}\")\n",
        "\n",
        "print(\"=\" * 50)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jupyter-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
